import tkinter as tk
from tkinter import ttk, filedialog, scrolledtext, messagebox
import threading
import os
import sys
import re
import subprocess
import logging
from pathlib import Path
from PIL import Image, ImageTk, ImageDraw, ImageFont
import torch

# ============ é‡è¦ï¼šå¿…é¡»åœ¨å¯¼å…¥ vLLM ä¹‹å‰è®¾ç½®ç¯å¢ƒå˜é‡ ============
os.environ['VLLM_USE_V1'] = '0'
os.environ["CUDA_VISIBLE_DEVICES"] = '0'

# CUDA ç‰ˆæœ¬ç‰¹å®šé…ç½®
if torch.version.cuda == '11.8':
    os.environ["TRITON_PTXAS_PATH"] = "/usr/local/cuda-11.8/bin/ptxas"

# ============ æ—¥å¿—ç³»ç»Ÿé…ç½® ============
# åˆ›å»ºæ—¥å¿—è®°å½•å™¨ï¼ˆç”¨äºåå°è¯¦ç»†æ—¥å¿—ï¼‰
logger = logging.getLogger("DeepSeekOCR")
logger.setLevel(logging.DEBUG)

# æ–‡ä»¶æ—¥å¿—å¤„ç†å™¨ï¼ˆè¯¦ç»†æŠ€æœ¯æ—¥å¿—ï¼‰
log_file = "deepseek_ocr_debug.log"
file_handler = logging.FileHandler(log_file, encoding='utf-8')
file_handler.setLevel(logging.DEBUG)
file_formatter = logging.Formatter(
    '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
file_handler.setFormatter(file_formatter)
logger.addHandler(file_handler)

# æ§åˆ¶å°æ—¥å¿—å¤„ç†å™¨ï¼ˆç³»ç»Ÿåˆå§‹åŒ–æ—¶æ‰“å°ï¼‰
console_handler = logging.StreamHandler()
console_handler.setLevel(logging.INFO)
console_formatter = logging.Formatter('%(levelname)s: %(message)s')
console_handler.setFormatter(console_formatter)
logger.addHandler(console_handler)

# ============ ç¡¬ä»¶æ£€æµ‹å‡½æ•° ============
def detect_gpu_driver():
    """
    æ£€æµ‹ NVIDIA GPU é©±åŠ¨ï¼ˆç”¨äº EXE åˆ†å‘ï¼‰
    æ³¨æ„ï¼šæ¯”æ£€æŸ¥ CUDA ç‰ˆæœ¬æ›´é è°±ï¼Œå› ä¸ºé©±åŠ¨å’Œ GPU è®¡ç®—èƒ½åŠ›å…³ç³»æ›´ç›´æ¥
    """
    gpu_driver_info = {
        "driver_installed": False,
        "driver_version": "æœªçŸ¥",
    }
    
    # å°è¯•æŸ¥è¯¢ NVIDIA é©±åŠ¨
    try:
        result = subprocess.run(
            ["nvidia-smi", "--query-gpu=driver_version", "--format=csv,noheader"],
            capture_output=True,
            text=True,
            timeout=5
        )
        if result.returncode == 0:
            driver_version = result.stdout.strip()
            if driver_version:
                gpu_driver_info["driver_installed"] = True
                gpu_driver_info["driver_version"] = driver_version
    except Exception as e:
        pass  # nvidia-smi ä¸å¯ç”¨
    
    return gpu_driver_info

def detect_hardware():
    """
    æ£€æµ‹ç³»ç»Ÿç¡¬ä»¶é…ç½®ï¼ˆé’ˆå¯¹ EXE ç¦»çº¿åˆ†å‘ä¼˜åŒ–ï¼‰
    
    å¯¹äº EXE åˆ†å‘ï¼š
    - æ£€æŸ¥ GPU ç¡¬ä»¶æ˜¯å¦å­˜åœ¨
    - æ£€æŸ¥é©±åŠ¨è€Œä¸æ˜¯ CUDA ç‰ˆæœ¬ï¼ˆé©±åŠ¨æ›´ç¨³å®šï¼‰
    - ä¸å¼ºåˆ¶ä¾èµ–ç‰¹å®š CUDA ç‰ˆæœ¬
    """
    gpu_driver_info = detect_gpu_driver()
    
    hardware_info = {
        # GPU ç¡¬ä»¶
        "cuda_available": torch.cuda.is_available(),
        "gpu_count": torch.cuda.device_count() if torch.cuda.is_available() else 0,
        "gpu_name": "",
        "gpu_memory_gb": "0",
        
        # é©±åŠ¨ä¿¡æ¯ï¼ˆç”¨äº EXE åˆ†å‘ï¼‰
        "driver_available": gpu_driver_info["driver_installed"],
        "driver_version": gpu_driver_info["driver_version"],
        
        # CUDA/cuDNN ä¿¡æ¯ï¼ˆå¯é€‰ï¼Œä»…ä¾›å‚è€ƒï¼‰
        "cuda_version": torch.version.cuda,
        "cudnn_version": torch.backends.cudnn.version() if torch.cuda.is_available() else None,
    }
    
    if hardware_info["cuda_available"] and hardware_info["gpu_count"] > 0:
        try:
            hardware_info["gpu_name"] = torch.cuda.get_device_name(0)
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024 ** 3)
            hardware_info["gpu_memory_gb"] = f"{gpu_memory:.2f}"
        except:
            hardware_info["gpu_memory_gb"] = "æœªçŸ¥"
    
    return hardware_info

# æ£€æµ‹ç¡¬ä»¶ä¿¡æ¯
HARDWARE_INFO = detect_hardware()

# ============ æ¨ç†å¼•æ“é€‰æ‹©é€»è¾‘ï¼ˆé’ˆå¯¹ EXE ç¦»çº¿åˆ†å‘ï¼‰ ============
# 
# ç­–ç•¥è¯´æ˜ï¼š
# 1. å¯¹äº CPU-Only ç‰ˆæœ¬ï¼šä½¿ç”¨ HuggingFace Transformersï¼ˆæ¨èåˆ†å‘ï¼‰
# 2. å¯¹äº GPU ç‰ˆæœ¬ï¼šæ£€æŸ¥é©±åŠ¨è€Œä¸æ˜¯ CUDA ç‰ˆæœ¬
# 3. ä»…åœ¨æœ‰ GPU é©±åŠ¨æ—¶æ‰å°è¯•åŠ è½½ vLLM

VLLM_AVAILABLE = False
HF_AVAILABLE = False

# ============ å†³ç­–é€»è¾‘ ============
# é»˜è®¤ä½¿ç”¨ Transformersï¼ˆCPU å‹å¥½ï¼‰
# ä»…å½“æœ‰ GPU é©±åŠ¨æ—¶æ‰è€ƒè™‘ vLLM

SHOULD_TRY_VLLM = HARDWARE_INFO["driver_available"] and HARDWARE_INFO["cuda_available"]

print("\n" + "="*70)
print("æ¨ç†å¼•æ“åˆå§‹åŒ–")
print("="*70)

# å°è¯•å¯¼å…¥ vLLMï¼ˆä»…åœ¨æœ‰ GPU æ—¶ï¼‰
if SHOULD_TRY_VLLM:
    print(f"âœ“ æ£€æµ‹åˆ° GPU é©±åŠ¨: v{HARDWARE_INFO['driver_version']}")
    print("å°è¯•åŠ è½½ vLLMï¼ˆé«˜æ€§èƒ½æ¨ç†ï¼‰...")
    
    try:
        # ç¯å¢ƒå˜é‡å·²åœ¨æ–‡ä»¶å¼€å¤´è®¾ç½®
        from vllm import LLM, SamplingParams
        from vllm.model_executor.models.registry import ModelRegistry
        from deepseek_ocr import DeepseekOCRForCausalLM
        from process.ngram_norepeat import NoRepeatNGramLogitsProcessor
        from process.image_process import DeepseekOCRProcessor
        
        ModelRegistry.register_model("DeepseekOCRForCausalLM", DeepseekOCRForCausalLM)
        VLLM_AVAILABLE = True
        print("âœ“ vLLM åŠ è½½æˆåŠŸ")
        
    except Exception as e:
        print(f"âš  vLLM åŠ è½½å¤±è´¥: {e}")
        print("é™çº§åˆ° HuggingFace Transformers...")
else:
    if HARDWARE_INFO["cuda_available"]:
        print("âœ“ æ£€æµ‹åˆ° GPUï¼Œä½†æœªæ£€æµ‹åˆ° NVIDIA é©±åŠ¨")
        print("  å»ºè®®ï¼šå®‰è£… NVIDIA é©±åŠ¨ä»¥è·å¾—æ›´å¥½çš„æ€§èƒ½")
        print("  ä½¿ç”¨ CPU æ¨¡å¼...")
    else:
        print("âœ“ ä½¿ç”¨ CPU æ¨¡å¼ï¼ˆæœªæ£€æµ‹åˆ° GPUï¼‰")

# å¦‚æœ vLLM ä¸å¯ç”¨ï¼Œä½¿ç”¨ HuggingFace Transformers
if not VLLM_AVAILABLE:
    try:
        from transformers import AutoModel, AutoTokenizer
        HF_AVAILABLE = True
        print("âœ“ ä½¿ç”¨ HuggingFace Transformers")
        if HARDWARE_INFO["cuda_available"]:
            print("  æ¨¡å¼: GPU åŠ é€Ÿ")
        else:
            print("  æ¨¡å¼: CPU æ¨ç†")
    except Exception as e:
        print(f"âœ— å¯¼å…¥å¤±è´¥: {e}")
        print("\nè¯·ç¡®ä¿å·²å®‰è£…ä¾èµ–åŒ…ï¼š")
        print("  pip install transformers")
        input("\næŒ‰ä»»æ„é”®é€€å‡º...")
        sys.exit(1)

if not VLLM_AVAILABLE and not HF_AVAILABLE:
    print("âœ— æ— æ³•å¯¼å…¥ä»»ä½•æ¨ç†å¼•æ“ï¼")
    input("\næŒ‰ä»»æ„é”®é€€å‡º...")
    sys.exit(1)

print("="*70 + "\n")


import fitz  # PyMuPDF
import io


class DeepSeekOCRVLLMGUI:
    def __init__(self, root):
        self.root = root
        engine_name = "vLLM" if VLLM_AVAILABLE else "HF Transformers"
        self.root.title(f"DeepSeek OCR GUI ({engine_name})")
        self.root.geometry("1200x800")
        
        # ç¡¬ä»¶ä¿¡æ¯
        self.hardware_info = HARDWARE_INFO
        
        # æ¨¡å‹ç›¸å…³å˜é‡
        self.llm = None
        self.model = None
        self.tokenizer = None
        self.model_loaded = False
        self.processing = False
        self.use_vllm = VLLM_AVAILABLE
        self.use_gpu = HARDWARE_INFO["cuda_available"]
        
        if VLLM_AVAILABLE:
            self.processor = DeepseekOCRProcessor()
        
        # åˆ›å»ºç•Œé¢
        self.create_widgets()
        
        # æ˜¾ç¤ºç¡¬ä»¶å’Œå¼•æ“ä¿¡æ¯
        self.show_hardware_info()
    
    def show_hardware_info(self):
        """æ˜¾ç¤ºç¡¬ä»¶å’Œæ¨ç†å¼•æ“ä¿¡æ¯ï¼ˆé’ˆå¯¹ EXE åˆ†å‘ä¼˜åŒ–ï¼‰"""
        self.log("\n" + "="*70, "info")
        self.log("ğŸ’» ç³»ç»Ÿç¡¬ä»¶æ£€æµ‹", "info")
        self.log("="*70, "info")
        
        # GPU é©±åŠ¨ä¿¡æ¯ï¼ˆæœ€é‡è¦ï¼‰
        self.log("\nã€GPU åŠ é€ŸçŠ¶æ€ã€‘", "info")
        if self.hardware_info["driver_available"]:
            self.log(f"âœ… NVIDIA é©±åŠ¨å·²å®‰è£…", "info")
            self.log(f"   é©±åŠ¨ç‰ˆæœ¬: {self.hardware_info['driver_version']}", "info", show_in_gui=False)
        else:
            self.log("âŒ NVIDIA é©±åŠ¨æœªæ£€æµ‹åˆ°", "info")
            if self.hardware_info["cuda_available"]:
                self.log("   ğŸ’¡ ä½ çš„ç”µè„‘æœ‰ GPUï¼Œä½†éœ€è¦å®‰è£…é©±åŠ¨æ¥åŠ é€Ÿè¿ç®—", "info")
                self.log("   ğŸ“ å»ºè®®: è®¿é—® https://www.nvidia.com/drivers ä¸‹è½½é©±åŠ¨", "info")
            else:
                self.log("   â„¹ï¸  ä½ çš„ç”µè„‘æ²¡æœ‰ NVIDIA GPUï¼Œå°†ä½¿ç”¨ CPUï¼ˆé€Ÿåº¦è¾ƒæ…¢ï¼‰", "info")
        
        # GPU ç¡¬ä»¶ä¿¡æ¯
        self.log("\nã€ç¡¬ä»¶é…ç½®ã€‘", "info")
        if self.hardware_info["cuda_available"] and self.hardware_info["gpu_count"] > 0:
            self.log(f"âœ… GPU: {self.hardware_info['gpu_name']}", "info")
            self.log(f"   æ˜¾å­˜: {self.hardware_info['gpu_memory_gb']} GB", "info", show_in_gui=False)
        else:
            self.log("â„¹ï¸  ä½¿ç”¨ CPU å¤„ç†ï¼ˆå»ºè®®é…ç½®: 8GB RAM ä»¥ä¸Šï¼‰", "info")
        
        # æ¨ç†å¼•æ“ä¿¡æ¯
        self.log("\nã€æ¨ç†å¼•æ“ã€‘", "info")
        if VLLM_AVAILABLE:
            self.log("âš¡ vLLMï¼ˆå¿«é€Ÿæ¨ç†ï¼‰", "info")
            self.log("   æ¨ç†é€Ÿåº¦: éå¸¸å¿« (~100+ tokens/ç§’)", "info")
            self.log("   é€‚ç”¨åœºæ™¯: æ—¥å¸¸ä½¿ç”¨ï¼Œå¤§æ‰¹é‡å¤„ç†", "info")
        elif HF_AVAILABLE:
            if self.use_gpu:
                self.log("ğŸš€ GPU åŠ é€Ÿæ¨ç†", "info")
                self.log("   æ¨ç†é€Ÿåº¦: ä¸­ç­‰ (~20-50 tokens/ç§’)", "info")
            else:
                self.log("ğŸ¢ CPU æ¨ç†ï¼ˆè¾ƒæ…¢ï¼‰", "info")
                self.log("   æ¨ç†é€Ÿåº¦: è¾ƒæ…¢ (~2-5 tokens/ç§’)", "info")
                self.log("   â±ï¸  ä¸€å¼  A4 çº¸å¯èƒ½éœ€è¦ 1-3 åˆ†é’Ÿ", "info")
        
        # è¯¦ç»†æŠ€æœ¯ä¿¡æ¯åªè¾“å‡ºåˆ°æ—¥å¿—æ–‡ä»¶
        if self.hardware_info["cuda_available"]:
            logger.info(f"CUDA ç‰ˆæœ¬: {self.hardware_info['cuda_version']}")
            if self.hardware_info['cudnn_version']:
                logger.info(f"cuDNN ç‰ˆæœ¬: {self.hardware_info['cudnn_version']}")
        
        self.log("="*70 + "\n", "info")
        self.log("âœ¨ å‡†å¤‡å°±ç»ªï¼è¯·ç‚¹å‡»\"åŠ è½½æ¨¡å‹\"å¼€å§‹ä½¿ç”¨\n", "info")
        
    def create_widgets(self):
        # ä¸»æ¡†æ¶
        main_frame = ttk.Frame(self.root, padding="10")
        main_frame.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))
        
        # é…ç½®è¡Œåˆ—æƒé‡
        self.root.columnconfigure(0, weight=1)
        self.root.rowconfigure(0, weight=1)
        main_frame.columnconfigure(1, weight=1)
        
        # æ ‡é¢˜
        engine_name = "vLLM" if VLLM_AVAILABLE else "HF Transformers"
        title_label = ttk.Label(main_frame, text=f"DeepSeek OCR å›¾åƒ/PDFè¯†åˆ«å·¥å…· ({engine_name})", 
                               font=("Arial", 16, "bold"))
        title_label.grid(row=0, column=0, columnspan=3, pady=10)
        
        # æ¨¡å‹é…ç½®åŒºåŸŸ
        model_frame = ttk.LabelFrame(main_frame, text="æ¨¡å‹é…ç½®", padding="10")
        model_frame.grid(row=1, column=0, columnspan=3, sticky=(tk.W, tk.E), pady=5)
        
        ttk.Label(model_frame, text="æ¨¡å‹è·¯å¾„:").grid(row=0, column=0, sticky=tk.W, padx=5)
        
        # æ£€æµ‹æœ¬åœ°æ¨¡å‹
        local_model_path = "./models/DeepSeek-OCR"
        if os.path.exists(local_model_path):
            default_model = local_model_path
            self.local_model_detected = True
        else:
            default_model = "deepseek-ai/DeepSeek-OCR"
            self.local_model_detected = False
        
        self.model_path_var = tk.StringVar(value=default_model)
        model_entry = ttk.Entry(model_frame, textvariable=self.model_path_var, width=50)
        model_entry.grid(row=0, column=1, sticky=(tk.W, tk.E), padx=5)
        
        self.load_model_btn = ttk.Button(model_frame, text="åŠ è½½æ¨¡å‹", command=self.load_model)
        self.load_model_btn.grid(row=0, column=2, padx=5)
        
        ttk.Button(model_frame, text="ğŸ“", command=self.browse_model_path, width=3).grid(row=0, column=3, padx=2)
        
        self.model_status_label = ttk.Label(model_frame, text="çŠ¶æ€: æœªåŠ è½½", foreground="red")
        self.model_status_label.grid(row=0, column=3, padx=5)
        
        # vLLMå‚æ•°
        ttk.Label(model_frame, text="GPUå†…å­˜åˆ©ç”¨ç‡:").grid(row=1, column=0, sticky=tk.W, padx=5)
        self.gpu_util_var = tk.DoubleVar(value=0.75)
        gpu_util_spin = ttk.Spinbox(model_frame, from_=0.1, to=0.95, increment=0.05, 
                                     textvariable=self.gpu_util_var, width=10)
        gpu_util_spin.grid(row=1, column=1, sticky=tk.W, padx=5)
        
        ttk.Label(model_frame, text="æœ€å¤§å¹¶å‘:").grid(row=1, column=2, sticky=tk.W, padx=5)
        self.max_concurrency_var = tk.IntVar(value=100)
        concurrency_spin = ttk.Spinbox(model_frame, from_=1, to=200, 
                                        textvariable=self.max_concurrency_var, width=10)
        concurrency_spin.grid(row=1, column=3, sticky=tk.W, padx=5)
        
        model_frame.columnconfigure(1, weight=1)
        
        # è¾“å…¥é…ç½®åŒºåŸŸ
        input_frame = ttk.LabelFrame(main_frame, text="è¾“å…¥é…ç½®", padding="10")
        input_frame.grid(row=2, column=0, columnspan=3, sticky=(tk.W, tk.E), pady=5)
        
        # æ–‡ä»¶ç±»å‹é€‰æ‹©
        ttk.Label(input_frame, text="è¾“å…¥ç±»å‹:").grid(row=0, column=0, sticky=tk.W, padx=5)
        self.input_type_var = tk.StringVar(value="image")
        type_frame = ttk.Frame(input_frame)
        type_frame.grid(row=0, column=1, sticky=tk.W, padx=5)
        ttk.Radiobutton(type_frame, text="å›¾ç‰‡", variable=self.input_type_var, 
                       value="image", command=self.on_input_type_change).pack(side=tk.LEFT, padx=5)
        ttk.Radiobutton(type_frame, text="PDF", variable=self.input_type_var, 
                       value="pdf", command=self.on_input_type_change).pack(side=tk.LEFT, padx=5)
        ttk.Radiobutton(type_frame, text="æ‰¹é‡å›¾ç‰‡", variable=self.input_type_var, 
                       value="batch", command=self.on_input_type_change).pack(side=tk.LEFT, padx=5)
        
        ttk.Label(input_frame, text="è¾“å…¥æ–‡ä»¶:").grid(row=1, column=0, sticky=tk.W, padx=5)
        self.input_path_var = tk.StringVar()
        input_entry = ttk.Entry(input_frame, textvariable=self.input_path_var, width=60)
        input_entry.grid(row=1, column=1, sticky=(tk.W, tk.E), padx=5)
        
        self.select_input_btn = ttk.Button(input_frame, text="é€‰æ‹©å›¾ç‰‡", command=self.select_input)
        self.select_input_btn.grid(row=1, column=2, padx=5)
        
        ttk.Label(input_frame, text="è¾“å‡ºç›®å½•:").grid(row=2, column=0, sticky=tk.W, padx=5)
        self.output_path_var = tk.StringVar(value="./output")
        output_entry = ttk.Entry(input_frame, textvariable=self.output_path_var, width=60)
        output_entry.grid(row=2, column=1, sticky=(tk.W, tk.E), padx=5)
        
        ttk.Button(input_frame, text="é€‰æ‹©ç›®å½•", command=self.select_output_dir).grid(row=2, column=2, padx=5)
        
        ttk.Label(input_frame, text="æç¤ºè¯:").grid(row=3, column=0, sticky=tk.W, padx=5)
        self.prompt_var = tk.StringVar(value="<image>\n<|grounding|>Convert the document to markdown.")
        prompt_combo = ttk.Combobox(input_frame, textvariable=self.prompt_var, width=58)
        prompt_combo['values'] = (
            "<image>\n<|grounding|>Convert the document to markdown.",
            "<image>\nFree OCR.",
            "<image>\n<|grounding|>OCR this image.",
            "<image>\nParse the figure.",
            "<image>\nDescribe this image in detail."
        )
        prompt_combo.grid(row=3, column=1, columnspan=2, sticky=(tk.W, tk.E), padx=5)
        
        # æç¤ºè¯å¸®åŠ©æŒ‰é’®
        ttk.Button(
            input_frame, 
            text="â“ å¸®åŠ©", 
            command=self.show_prompt_help,
            width=6
        ).grid(row=3, column=3, sticky=tk.W, padx=2)
        
        input_frame.columnconfigure(1, weight=1)
        
        # å‚æ•°é…ç½®åŒºåŸŸ
        param_frame = ttk.LabelFrame(main_frame, text="OCRå‚æ•°", padding="10")
        param_frame.grid(row=3, column=0, columnspan=3, sticky=(tk.W, tk.E), pady=5)
        
        # ç¬¬ä¸€è¡Œå‚æ•°
        ttk.Label(param_frame, text="base_size:").grid(row=0, column=0, sticky=tk.W, padx=5)
        self.base_size_var = tk.IntVar(value=1024)
        base_size_combo = ttk.Combobox(param_frame, textvariable=self.base_size_var, 
                                       values=[512, 640, 1024, 1280], width=10, state="readonly")
        base_size_combo.grid(row=0, column=1, sticky=tk.W, padx=5)
        
        ttk.Label(param_frame, text="image_size:").grid(row=0, column=2, sticky=tk.W, padx=5)
        self.image_size_var = tk.IntVar(value=640)
        image_size_combo = ttk.Combobox(param_frame, textvariable=self.image_size_var, 
                                        values=[512, 640, 1024, 1280], width=10, state="readonly")
        image_size_combo.grid(row=0, column=3, sticky=tk.W, padx=5)
        
        ttk.Label(param_frame, text="PDF DPI:").grid(row=0, column=4, sticky=tk.W, padx=5)
        self.pdf_dpi_var = tk.IntVar(value=144)
        pdf_dpi_combo = ttk.Combobox(param_frame, textvariable=self.pdf_dpi_var, 
                                     values=[72, 96, 144, 200, 300], width=10, state="readonly")
        pdf_dpi_combo.grid(row=0, column=5, sticky=tk.W, padx=5)
        
        # ç¬¬äºŒè¡Œå‚æ•°
        self.crop_mode_var = tk.BooleanVar(value=True)
        ttk.Checkbutton(param_frame, text="Crop Mode", variable=self.crop_mode_var).grid(
            row=1, column=0, columnspan=2, sticky=tk.W, padx=5, pady=5)
        
        self.save_results_var = tk.BooleanVar(value=True)
        ttk.Checkbutton(param_frame, text="ä¿å­˜ç»“æœ", variable=self.save_results_var).grid(
            row=1, column=2, columnspan=2, sticky=tk.W, padx=5, pady=5)
        
        self.save_visualization_var = tk.BooleanVar(value=True)
        ttk.Checkbutton(param_frame, text="ä¿å­˜å¯è§†åŒ–", variable=self.save_visualization_var).grid(
            row=1, column=4, columnspan=2, sticky=tk.W, padx=5, pady=5)
        
        # é¢„è®¾é…ç½®
        ttk.Label(param_frame, text="é¢„è®¾é…ç½®:").grid(row=2, column=0, sticky=tk.W, padx=5)
        preset_combo = ttk.Combobox(param_frame, values=["Gundam", "Tiny", "Small", "Base", "Large"], 
                                    width=10, state="readonly")
        preset_combo.grid(row=2, column=1, sticky=tk.W, padx=5)
        preset_combo.bind("<<ComboboxSelected>>", self.apply_preset)
        
        # æ‰§è¡ŒæŒ‰é’®
        button_frame = ttk.Frame(main_frame)
        button_frame.grid(row=4, column=0, columnspan=3, pady=10)
        
        self.run_btn = ttk.Button(button_frame, text="å¼€å§‹è¯†åˆ«", command=self.run_ocr, 
                                  state=tk.DISABLED, style="Accent.TButton")
        self.run_btn.pack(side=tk.LEFT, padx=5)
        
        self.stop_btn = ttk.Button(button_frame, text="åœæ­¢", command=self.stop_ocr, 
                                   state=tk.DISABLED)
        self.stop_btn.pack(side=tk.LEFT, padx=5)
        
        ttk.Button(button_frame, text="æ¸…ç©ºæ—¥å¿—", command=self.clear_log).pack(side=tk.LEFT, padx=5)
        
        ttk.Button(button_frame, text="æ‰“å¼€è¾“å‡ºç›®å½•", command=self.open_output_dir).pack(side=tk.LEFT, padx=5)
        
        # è¿›åº¦æ¡
        self.progress = ttk.Progressbar(main_frame, mode='indeterminate')
        self.progress.grid(row=5, column=0, columnspan=3, sticky=(tk.W, tk.E), pady=5)
        
        # æ—¥å¿—è¾“å‡ºåŒºåŸŸ
        log_frame = ttk.LabelFrame(main_frame, text="è¿è¡Œæ—¥å¿—", padding="10")
        log_frame.grid(row=6, column=0, columnspan=3, sticky=(tk.W, tk.E, tk.N, tk.S), pady=5)
        main_frame.rowconfigure(6, weight=1)
        
        self.log_text = scrolledtext.ScrolledText(log_frame, height=20, wrap=tk.WORD)
        self.log_text.pack(fill=tk.BOTH, expand=True)
        
        # åœ¨æ—¥å¿—åˆ›å»ºåè¾“å‡ºæœ¬åœ°æ¨¡å‹æ£€æµ‹ä¿¡æ¯
        if hasattr(self, 'local_model_detected') and self.local_model_detected:
            self.log(f"âœ“ æ£€æµ‹åˆ°æœ¬åœ°æ¨¡å‹: ./models/DeepSeek-OCR")
        
    def log(self, message, level="info", show_in_gui=True):
        """
        åŒå±‚æ—¥å¿—ç³»ç»Ÿï¼š
        - GUI ç•Œé¢æ˜¾ç¤ºç”¨æˆ·å‹å¥½çš„ä¿¡æ¯
        - åå°è¯¦ç»†æ—¥å¿—è®°å½•æŠ€æœ¯ä¿¡æ¯
        
        å‚æ•°ï¼š
            message: æ—¥å¿—æ¶ˆæ¯
            level: æ—¥å¿—çº§åˆ« ("debug", "info", "warning", "error")
            show_in_gui: æ˜¯å¦åœ¨ GUI ä¸­æ˜¾ç¤ºï¼ˆFalse æ—¶åªè®°å½•åˆ°æ–‡ä»¶ï¼‰
        """
        # åå°è¯¦ç»†æ—¥å¿—ï¼ˆæŠ€æœ¯äººå‘˜æŸ¥çœ‹ï¼‰
        if level == "debug":
            logger.debug(message)
        elif level == "warning":
            logger.warning(message)
        elif level == "error":
            logger.error(message)
        else:
            logger.info(message)
        
        # GUI æ˜¾ç¤ºç”¨æˆ·å‹å¥½çš„ä¿¡æ¯
        if show_in_gui:
            self.log_text.insert(tk.END, f"{message}\n")
            self.log_text.see(tk.END)
            self.root.update_idletasks()
        
    def clear_log(self):
        """æ¸…ç©ºæ—¥å¿—"""
        self.log_text.delete(1.0, tk.END)
    
    def browse_model_path(self):
        """æµè§ˆé€‰æ‹©æœ¬åœ°æ¨¡å‹ç›®å½•"""
        directory = filedialog.askdirectory(
            title="é€‰æ‹©æ¨¡å‹æ–‡ä»¶å¤¹",
            initialdir="./models" if os.path.exists("./models") else "."
        )
        if directory:
            self.model_path_var.set(directory)
            self.log(f"å·²é€‰æ‹©æ¨¡å‹è·¯å¾„: {directory}")
            # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            config_file = os.path.join(directory, "config.json")
            if os.path.exists(config_file):
                self.log("âœ“ æ¨¡å‹æ–‡ä»¶éªŒè¯æˆåŠŸ")
            else:
                self.log("âš  è­¦å‘Š: æœªæ‰¾åˆ° config.jsonï¼Œè¿™å¯èƒ½ä¸æ˜¯æœ‰æ•ˆçš„æ¨¡å‹ç›®å½•")
        
    def on_input_type_change(self):
        """è¾“å…¥ç±»å‹æ”¹å˜æ—¶æ›´æ–°æŒ‰é’®æ–‡æœ¬"""
        input_type = self.input_type_var.get()
        if input_type == "image":
            self.select_input_btn.config(text="é€‰æ‹©å›¾ç‰‡")
        elif input_type == "pdf":
            self.select_input_btn.config(text="é€‰æ‹©PDF")
        else:  # batch
            self.select_input_btn.config(text="é€‰æ‹©æ–‡ä»¶å¤¹")
            
    def select_input(self):
        """é€‰æ‹©è¾“å…¥æ–‡ä»¶"""
        input_type = self.input_type_var.get()
        if input_type == "image":
            filename = filedialog.askopenfilename(
                title="é€‰æ‹©å›¾åƒæ–‡ä»¶",
                filetypes=[("å›¾åƒæ–‡ä»¶", "*.jpg *.jpeg *.png *.bmp *.tiff"), ("æ‰€æœ‰æ–‡ä»¶", "*.*")]
            )
            if filename:
                self.input_path_var.set(filename)
                self.log(f"å·²é€‰æ‹©å›¾åƒ: {filename}")
        elif input_type == "pdf":
            filename = filedialog.askopenfilename(
                title="é€‰æ‹©PDFæ–‡ä»¶",
                filetypes=[("PDFæ–‡ä»¶", "*.pdf"), ("æ‰€æœ‰æ–‡ä»¶", "*.*")]
            )
            if filename:
                self.input_path_var.set(filename)
                self.log(f"å·²é€‰æ‹©PDF: {filename}")
        else:  # batch
            directory = filedialog.askdirectory(title="é€‰æ‹©å›¾ç‰‡æ–‡ä»¶å¤¹")
            if directory:
                self.input_path_var.set(directory)
                self.log(f"å·²é€‰æ‹©æ–‡ä»¶å¤¹: {directory}")
            
    def select_output_dir(self):
        """é€‰æ‹©è¾“å‡ºç›®å½•"""
        directory = filedialog.askdirectory(title="é€‰æ‹©è¾“å‡ºç›®å½•")
        if directory:
            self.output_path_var.set(directory)
            self.log(f"è¾“å‡ºç›®å½•: {directory}")
    def open_output_dir(self):
        """æ‰“å¼€è¾“å‡ºç›®å½•ï¼ˆè·¨å¹³å°ï¼‰"""
        output_path = self.output_path_var.get()
        if os.path.exists(output_path):
            try:
                if sys.platform == 'win32':
                    os.startfile(output_path)
                elif sys.platform == 'darwin':  # macOS
                    subprocess.Popen(['open', output_path])
                else:  # Linux
                    subprocess.Popen(['xdg-open', output_path])
            except Exception as e:
                self.log(f"æ— æ³•æ‰“å¼€ç›®å½•: {e}")
                messagebox.showinfo("æç¤º", f"è¾“å‡ºç›®å½•: {output_path}")
        else:
            messagebox.showwarning("è­¦å‘Š", f"è¾“å‡ºç›®å½•ä¸å­˜åœ¨: {output_path}")
            messagebox.showwarning("è­¦å‘Š", f"è¾“å‡ºç›®å½•ä¸å­˜åœ¨: {output_path}")
            
    def apply_preset(self, event):
        """åº”ç”¨é¢„è®¾é…ç½®"""
        preset = event.widget.get()
        presets = {
            "Tiny": (512, 512, False),
            "Small": (640, 640, False),
            "Base": (1024, 1024, False),
            "Large": (1280, 1280, False),
            "Gundam": (1024, 640, True)
        }
        if preset in presets:
            base_size, image_size, crop_mode = presets[preset]
            self.base_size_var.set(base_size)
            self.image_size_var.set(image_size)
            self.crop_mode_var.set(crop_mode)
    
    def show_prompt_help(self):
        """æ˜¾ç¤ºæç¤ºè¯å¸®åŠ©ä¿¡æ¯"""
        help_text = """
ã€æç¤ºè¯ (Prompt) è¯´æ˜ã€‘

æç¤ºè¯æ˜¯å‘Šè¯‰ AI ä½ æƒ³è¦ä»€ä¹ˆçš„æŒ‡ä»¤ã€‚ä»¥ä¸‹æ˜¯å¸¸ç”¨æç¤ºè¯ï¼š

1ï¸âƒ£ è½¬æ¢ä¸º Markdown æ ¼å¼ï¼ˆæ¨èï¼‰
   <image>
   <|grounding|>Convert the document to markdown.
   ğŸ‘‰ ç”¨é€”ï¼šå°†æ–‡æ¡£è½¬ä¸º Markdown æ ¼å¼
   
2ï¸âƒ£ è‡ªç”± OCR è¯†åˆ«
   <image>
   Free OCR.
   ğŸ‘‰ ç”¨é€”ï¼šæå–æ–‡æœ¬å†…å®¹
   
3ï¸âƒ£ è¯¦ç»† OCR è¯†åˆ«
   <image>
   <|grounding|>OCR this image.
   ğŸ‘‰ ç”¨é€”ï¼šç²¾ç¡®è¯†åˆ«æ¯ä¸ªå­—ç¬¦
   
4ï¸âƒ£ è§£æå›¾è¡¨
   <image>
   Parse the figure.
   ğŸ‘‰ ç”¨é€”ï¼šè¯†åˆ«å›¾è¡¨å’Œæ•°æ®
   
5ï¸âƒ£ æè¿°å›¾åƒ
   <image>
   Describe this image in detail.
   ğŸ‘‰ ç”¨é€”ï¼šç”Ÿæˆè¯¦ç»†çš„å›¾åƒæè¿°

ğŸ“Œ æç¤ºï¼š
â€¢ <image> æ˜¯å›ºå®šçš„ï¼Œä»£è¡¨ä½ è¦è¯†åˆ«çš„å›¾ç‰‡
â€¢ é€‰æ‹©åˆé€‚çš„æç¤ºè¯èƒ½è·å¾—æ›´å¥½çš„è¯†åˆ«æ•ˆæœ
â€¢ é»˜è®¤æ¨è"Convert to markdown"
"""
        messagebox.showinfo("æç¤ºè¯å¸®åŠ©", help_text)
    
    def load_model(self):
        """åŠ è½½æ¨¡å‹ï¼ˆvLLMæˆ–HFï¼‰"""
        if self.model_loaded:
            self.log("æ¨¡å‹å·²ç»åŠ è½½")
            return
            
        def load_thread():
            try:
                self.load_model_btn.config(state=tk.DISABLED)
                model_path = self.model_path_var.get()
                
                # æ£€æŸ¥æ¨¡å‹è·¯å¾„æ˜¯å¦å­˜åœ¨ï¼ˆæœ¬åœ°æ¨¡å‹ï¼‰
                if os.path.exists(model_path):
                    self.log(f"ğŸ“‚ ä½¿ç”¨æœ¬åœ°æ¨¡å‹: {model_path}", "info")
                    self.log("âœ… ç¦»çº¿æ¨¡å¼ï¼ˆæ— éœ€ç½‘ç»œè¿æ¥ï¼‰", "info")
                else:
                    self.log(f"ğŸ”„ æ¨¡å‹è·¯å¾„: {model_path}", "info")
                    self.log("âš ï¸  åœ¨çº¿æ¨¡å¼ï¼ˆéœ€è¦ç½‘ç»œä¸‹è½½ï¼Œå¯èƒ½è¾ƒæ…¢ï¼‰", "info")
                
                # è¯¦ç»†æ—¥å¿—è¾“å‡ºåˆ°æ–‡ä»¶
                logger.debug(f"æ¨¡å‹åŠ è½½è·¯å¾„: {model_path}")
                logger.debug(f"CUDA è®¾å¤‡: {os.environ.get('CUDA_VISIBLE_DEVICES', '0')}")
                
                # è®¾ç½®CUDAè®¾å¤‡
                os.environ["CUDA_VISIBLE_DEVICES"] = '0'
                
                # è®¾ç½®ç¦»çº¿æ¨¡å¼ï¼ˆå¦‚æœæ˜¯æœ¬åœ°è·¯å¾„ï¼‰
                if os.path.exists(model_path):
                    os.environ["HF_HUB_OFFLINE"] = "1"
                    os.environ["TRANSFORMERS_OFFLINE"] = "1"
                
                if self.use_vllm:
                    # ä½¿ç”¨ vLLM
                    self.log("\nâ³ æ­£åœ¨åŠ è½½æ¨¡å‹ï¼ˆè¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼‰...", "info")
                    self.log("ğŸ’¡ åˆå§‹åŒ–æ¨ç†å¼•æ“...", "info", show_in_gui=False)
                    
                    # æ£€æŸ¥ GPU æ˜¯å¦å¯ç”¨
                    if not self.use_gpu:
                        self.log("âš ï¸  è­¦å‘Š: GPU é©±åŠ¨æœªæ£€æµ‹åˆ°", "warning")
                        self.log("       vLLM å¯èƒ½æ— æ³•è¿è¡Œï¼Œå»ºè®®å®‰è£… NVIDIA é©±åŠ¨", "warning")
                    
                    self.llm = LLM(
                        model=model_path,
                        hf_overrides={"architectures": ["DeepseekOCRForCausalLM"]},
                        block_size=256,
                        enforce_eager=False,
                        trust_remote_code=True, 
                        max_model_len=8192,
                        swap_space=0,
                        max_num_seqs=self.max_concurrency_var.get(),
                        tensor_parallel_size=1,
                        gpu_memory_utilization=self.gpu_util_var.get(),
                        dtype="bfloat16",  # æ˜ç¡®æŒ‡å®šæ•°æ®ç±»å‹ï¼Œé¿å… float16/bfloat16 æ··ç”¨
                    )
                    
                    self.model_status_label.config(text="âœ… å·²åŠ è½½ (vLLM)", foreground="green")
                    self.log("âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼", "info")
                    self.log(f"âš¡ æ¨ç†æ¨¡å¼: vLLMï¼ˆé«˜é€Ÿï¼‰", "info")
                    
                    # è¯¦ç»†é…ç½®ä¿¡æ¯åˆ°æ—¥å¿—æ–‡ä»¶
                    logger.info(f"GPUå†…å­˜åˆ©ç”¨ç‡: {self.gpu_util_var.get()}")
                    logger.info(f"æœ€å¤§å¹¶å‘æ•°: {self.max_concurrency_var.get()}")
                    
                else:
                    # ä½¿ç”¨ HuggingFace Transformers
                    self.log("\nâ³ æ­£åœ¨åŠ è½½æ¨¡å‹ï¼ˆè¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼‰...", "info")
                    self.log("ğŸ’¡ åŠ è½½ tokenizer...", "info", show_in_gui=False)
                    self.tokenizer = AutoTokenizer.from_pretrained(
                        model_path, 
                        trust_remote_code=True,
                        local_files_only=os.path.exists(model_path)
                    )
                    
                    self.log("ğŸ’¡ åŠ è½½æ¨¡å‹æƒé‡...", "info", show_in_gui=False)
                    self.model = AutoModel.from_pretrained(
                        model_path,
                        trust_remote_code=True, 
                        use_safetensors=True,
                        local_files_only=os.path.exists(model_path)
                    )
                    
                    # æ£€æŸ¥CUDAæ˜¯å¦å¯ç”¨
                    if self.use_gpu:
                        self.log("ğŸ’¡ æ­£åœ¨åŠ è½½åˆ° GPU...", "info", show_in_gui=False)
                        try:
                            self.model = self.model.eval().cuda().to(torch.bfloat16)
                            self.log("âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼", "info")
                            self.log("âš¡ æ¨ç†æ¨¡å¼: GPU åŠ é€Ÿ", "info")
                            self.log(f"   GPU: {self.hardware_info['gpu_name']}", "info", show_in_gui=False)
                            logger.info("æ¨¡å‹åŠ è½½åˆ° GPUï¼Œä½¿ç”¨ bfloat16 ç²¾åº¦")
                        except RuntimeError as gpu_err:
                            self.log(f"âš ï¸  GPU åŠ è½½å¤±è´¥ï¼Œè‡ªåŠ¨é™çº§åˆ° CPU", "warning")
                            self.log(f"     é”™è¯¯: {str(gpu_err)[:50]}...", "debug", show_in_gui=False)
                            self.model = self.model.eval()
                            self.use_gpu = False
                    else:
                        self.log("âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼", "info")
                        self.log("ğŸ¢ æ¨ç†æ¨¡å¼: CPUï¼ˆè¾ƒæ…¢ï¼‰", "info")
                        self.log("   æç¤º: å»ºè®®å®‰è£… NVIDIA é©±åŠ¨ä»¥è·å¾—æ›´å¿«é€Ÿåº¦", "info")
                        self.model = self.model.eval()
                    
                    self.model_status_label.config(text="âœ… å·²åŠ è½½ (HF)", foreground="green")
                
                self.model_loaded = True
                self.run_btn.config(state=tk.NORMAL)
                self.log("\nâœ¨ ç°åœ¨å¯ä»¥å¼€å§‹å¤„ç†æ–‡ä»¶äº†ï¼", "info")
                
            except Exception as e:
                error_msg = str(e)
                self.log(f"\nâŒ åŠ è½½å¤±è´¥", "error")
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯ç½‘ç»œè¿æ¥é—®é¢˜
                if "Connection" in error_msg or "timeout" in error_msg or "huggingface.co" in error_msg:
                    self.log("ğŸ“¡ åŸå› : ç½‘ç»œè¿æ¥å¤±è´¥", "error")
                    self.log("\nğŸ’¡ è§£å†³æ–¹æ¡ˆ:", "info")
                    self.log("1. ä½¿ç”¨æœ¬åœ°æ¨¡å‹ï¼ˆæ¨èï¼‰:", "info")
                    self.log("   â€¢ å…ˆåœ¨æœ‰ç½‘ç»œçš„ç”µè„‘ä¸‹è½½æ¨¡å‹", "info")
                    self.log("   â€¢ å°†æ¨¡å‹æ–‡ä»¶å¤åˆ¶åˆ° ./models æ–‡ä»¶å¤¹", "info")
                    self.log("   â€¢ é‡æ–°åŠ è½½", "info")
                    self.log("2. æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œé˜²ç«å¢™", "info")
                    self.log("3. å¦‚éœ€åœ¨çº¿ä¸‹è½½ï¼Œè¯·ç¨åé‡è¯•", "info")
                else:
                    self.log(f"ğŸ“‹ é”™è¯¯ä¿¡æ¯: {error_msg}", "error")
                    logger.error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {error_msg}", exc_info=True)
                    self.log("ğŸ’¡ è¯·æŸ¥çœ‹ç¨‹åºç›®å½•ä¸‹çš„ deepseek_ocr_debug.log è·å–è¯¦ç»†ä¿¡æ¯", "info")
                
                self.model_status_label.config(text="âŒ åŠ è½½å¤±è´¥", foreground="red")
            finally:
                self.load_model_btn.config(state=tk.NORMAL)
        
        # åœ¨æ–°çº¿ç¨‹ä¸­å¯åŠ¨æ¨¡å‹åŠ è½½
        thread = threading.Thread(target=load_thread, daemon=True)
        thread.start()
    
    def process_single_image(self, image_path, output_path):
        """å¤„ç†å•å¼ å›¾ç‰‡"""
        self.log(f"åŠ è½½å›¾ç‰‡: {image_path}")
        image = Image.open(image_path).convert('RGB')
        
        if self.use_vllm:
            # vLLM å¤„ç†
            self.log("å¤„ç†å›¾åƒç‰¹å¾...")
            image_features = self.processor.tokenize_with_images(
                images=[image], 
                bos=True, 
                eos=True, 
                cropping=self.crop_mode_var.get()
            )
            
            # å‡†å¤‡é‡‡æ ·å‚æ•°
            logits_processors = [NoRepeatNGramLogitsProcessor(
                ngram_size=30, 
                window_size=90, 
                whitelist_token_ids={128821, 128822}
            )]
            
            sampling_params = SamplingParams(
                temperature=0.0,
                max_tokens=8192,
                logits_processors=logits_processors,
                skip_special_tokens=False,
            )
            
            # ç”Ÿæˆç»“æœ
            self.log("å¼€å§‹OCRè¯†åˆ«...")
            request = {
                "prompt": self.prompt_var.get(),
                "multi_modal_data": {"image": image_features}
            }
            
            outputs = self.llm.generate(request, sampling_params)
            result = outputs[0].outputs[0].text
        else:
            # HuggingFace å¤„ç†
            self.log("å¼€å§‹OCRè¯†åˆ«...")
            result = self.model.infer(
                self.tokenizer,
                prompt=self.prompt_var.get(),
                image_file=image_path,
                output_path=output_path,
                base_size=self.base_size_var.get(),
                image_size=self.image_size_var.get(),
                crop_mode=self.crop_mode_var.get(),
                save_results=False,  # æˆ‘ä»¬è‡ªå·±ä¿å­˜
                test_compress=False
            )
        
        # ä¿å­˜ç»“æœ
        if self.save_results_var.get():
            os.makedirs(output_path, exist_ok=True)
            os.makedirs(f'{output_path}/images', exist_ok=True)
            
            # ä¿å­˜åŸå§‹ç»“æœ
            with open(f'{output_path}/result.md', 'w', encoding='utf-8') as f:
                f.write(result)
            
            self.log(f"ç»“æœå·²ä¿å­˜åˆ°: {output_path}/result.md")
        
        return result
    
    def pdf_to_images(self, pdf_path, dpi=144):
        """
        å°†PDFè½¬æ¢ä¸ºé«˜è´¨é‡å›¾åƒ
        ä½¿ç”¨ä¸ run_dpsk_ocr_pdf.py ç›¸åŒçš„å®ç°
        """
        import fitz
        import io
        
        self.log(f"æ‰“å¼€PDFæ–‡ä»¶: {pdf_path}")
        
        images = []
        pdf_document = fitz.open(pdf_path)
        
        self.log(f"PDFå…± {pdf_document.page_count} é¡µï¼Œå¼€å§‹è½¬æ¢ (DPI={dpi})...")
        
        zoom = dpi / 72.0
        matrix = fitz.Matrix(zoom, zoom)
        
        for page_num in range(pdf_document.page_count):
            page = pdf_document[page_num]
            
            # æ¸²æŸ“ä¸ºé«˜è´¨é‡å›¾åƒ
            pixmap = page.get_pixmap(matrix=matrix, alpha=False)
            Image.MAX_IMAGE_PIXELS = None
            
            # è½¬æ¢ä¸ºPNGæ ¼å¼
            img_data = pixmap.tobytes("png")
            img = Image.open(io.BytesIO(img_data))
            
            images.append(img)
            
            if (page_num + 1) % 10 == 0:
                self.log(f"  å·²è½¬æ¢ {page_num + 1}/{pdf_document.page_count} é¡µ")
        
        pdf_document.close()
        self.log(f"âœ“ PDFè½¬æ¢å®Œæˆï¼Œå…± {len(images)} é¡µ")
        
        return images
        
    def process_pdf(self, pdf_path, output_path):
        """å¤„ç†PDFæ–‡ä»¶"""
        # è½¬æ¢PDFä¸ºå›¾åƒ
        images = self.pdf_to_images(pdf_path, self.pdf_dpi_var.get())
        
        os.makedirs(output_path, exist_ok=True)
        
        # å¤„ç†æ¯ä¸€é¡µ
        all_results = []
        for page_num, image in enumerate(images, 1):
            self.log(f"\n{'='*50}")
            self.log(f"è¯†åˆ«ç¬¬ {page_num}/{len(images)} é¡µ")
            self.log(f"{'='*50}")
            
            if self.use_vllm:
                # vLLM å¤„ç†
                image_features = self.processor.tokenize_with_images(
                    images=[image], 
                    bos=True, 
                    eos=True, 
                    cropping=self.crop_mode_var.get()
                )
                
                logits_processors = [NoRepeatNGramLogitsProcessor(
                    ngram_size=20, 
                    window_size=50, 
                    whitelist_token_ids={128821, 128822}
                )]
                
                sampling_params = SamplingParams(
                    temperature=0.0,
                    max_tokens=8192,
                    logits_processors=logits_processors,
                    skip_special_tokens=False,
                )
                
                request = {
                    "prompt": self.prompt_var.get(),
                    "multi_modal_data": {"image": image_features}
                }
                
                outputs = self.llm.generate(request, sampling_params)
                result = outputs[0].outputs[0].text
            else:
                # HuggingFace å¤„ç† - ä¿å­˜ä¸´æ—¶æ–‡ä»¶
                temp_image_path = f"{output_path}/temp_page_{page_num}.jpg"
                image.save(temp_image_path)
                
                result = self.model.infer(
                    self.tokenizer,
                    prompt=self.prompt_var.get(),
                    image_file=temp_image_path,
                    output_path=output_path,
                    base_size=self.base_size_var.get(),
                    image_size=self.image_size_var.get(),
                    crop_mode=self.crop_mode_var.get(),
                    save_results=False,
                    test_compress=False
                )
                
                # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
                try:
                    os.remove(temp_image_path)
                except:
                    pass
            
            all_results.append(f"# Page {page_num}\n\n{result}\n\n")
            
            # ä¿å­˜å•é¡µç»“æœ
            if self.save_results_var.get():
                page_output = f"{output_path}/page_{page_num:03d}.md"
                with open(page_output, 'w', encoding='utf-8') as f:
                    f.write(result)
                self.log(f"ç¬¬ {page_num} é¡µå·²ä¿å­˜")
        
        # ä¿å­˜åˆå¹¶ç»“æœ
        if self.save_results_var.get():
            combined_output = f"{output_path}/all_pages.md"
            with open(combined_output, 'w', encoding='utf-8') as f:
                f.writelines(all_results)
            self.log(f"\næ‰€æœ‰é¡µé¢å·²åˆå¹¶ä¿å­˜åˆ°: {combined_output}")
        
        return '\n'.join(all_results)
        
    def process_batch_images(self, folder_path, output_path):
        """æ‰¹é‡å¤„ç†å›¾ç‰‡æ–‡ä»¶å¤¹"""
        # è·å–æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶
        image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']
        image_files = []
        for ext in image_extensions:
            image_files.extend(Path(folder_path).glob(f'*{ext}'))
            image_files.extend(Path(folder_path).glob(f'*{ext.upper()}'))
        
        image_files = sorted(list(set(image_files)))
        total = len(image_files)
        
        if total == 0:
            self.log("æœªæ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶ï¼")
            return
        
        self.log(f"æ‰¾åˆ° {total} ä¸ªå›¾ç‰‡æ–‡ä»¶")
        os.makedirs(output_path, exist_ok=True)
        
        # å¤„ç†æ¯å¼ å›¾ç‰‡
        for idx, image_file in enumerate(image_files, 1):
            self.log(f"\n{'='*50}")
            self.log(f"å¤„ç† {idx}/{total}: {image_file.name}")
            self.log(f"{'='*50}")
            
            try:
                result = self.process_single_image(str(image_file), output_path)
                
                # ä¿å­˜ç»“æœ
                if self.save_results_var.get():
                    output_file = f"{output_path}/{image_file.stem}.md"
                    with open(output_file, 'w', encoding='utf-8') as f:
                        f.write(result)
                    self.log(f"ç»“æœå·²ä¿å­˜: {output_file}")
                    
            except Exception as e:
                self.log(f"å¤„ç†å¤±è´¥: {str(e)}")
                continue
        
        self.log(f"\næ‰¹é‡å¤„ç†å®Œæˆï¼å…±å¤„ç† {total} ä¸ªæ–‡ä»¶")
        
    def run_ocr(self):
        """è¿è¡ŒOCRè¯†åˆ«"""
        if not self.model_loaded:
            messagebox.showwarning("è­¦å‘Š", "è¯·å…ˆåŠ è½½æ¨¡å‹ï¼")
            return
            
        if not self.input_path_var.get():
            messagebox.showwarning("è­¦å‘Š", "è¯·å…ˆé€‰æ‹©è¾“å…¥æ–‡ä»¶ï¼")
            return
            
        if self.processing:
            messagebox.showwarning("è­¦å‘Š", "æ­£åœ¨å¤„ç†ä¸­ï¼Œè¯·ç­‰å¾…...")
            return
            
        def ocr_thread():
            try:
                self.processing = True
                self.run_btn.config(state=tk.DISABLED)
                self.stop_btn.config(state=tk.NORMAL)
                self.progress.start()
                
                self.log("="*70)
                self.log(f"å¼€å§‹OCRè¯†åˆ« - {self.input_type_var.get().upper()}æ¨¡å¼")
                self.log("="*70)
                self.log(f"è¾“å…¥: {self.input_path_var.get()}")
                self.log(f"è¾“å‡º: {self.output_path_var.get()}")
                self.log(f"æç¤ºè¯: {self.prompt_var.get()}")
                
                input_type = self.input_type_var.get()
                input_path = self.input_path_var.get()
                output_path = self.output_path_var.get()
                
                if input_type == "image":
                    result = self.process_single_image(input_path, output_path)
                elif input_type == "pdf":
                    result = self.process_pdf(input_path, output_path)
                else:  # batch
                    self.process_batch_images(input_path, output_path)
                    result = "æ‰¹é‡å¤„ç†å®Œæˆ"
                
                self.log("\n" + "="*70)
                self.log("è¯†åˆ«å®Œæˆï¼")
                self.log("="*70)
                
                messagebox.showinfo("å®Œæˆ", "OCRè¯†åˆ«å®Œæˆï¼")
                
            except Exception as e:
                self.log(f"\nè¯†åˆ«å¤±è´¥: {str(e)}")
                import traceback
                self.log(traceback.format_exc())
                messagebox.showerror("é”™è¯¯", f"OCRè¯†åˆ«å¤±è´¥:\n{str(e)}")
            finally:
                self.processing = False
                self.run_btn.config(state=tk.NORMAL)
                self.stop_btn.config(state=tk.DISABLED)
                self.progress.stop()
        
        # åœ¨æ–°çº¿ç¨‹ä¸­è¿è¡ŒOCR
        thread = threading.Thread(target=ocr_thread, daemon=True)
        thread.start()
        
    def stop_ocr(self):
        """åœæ­¢OCRè¯†åˆ«"""
        self.log("è¯·æ±‚åœæ­¢è¯†åˆ«...")
        messagebox.showinfo("æç¤º", "å·²å‘é€åœæ­¢è¯·æ±‚ï¼Œä½†å¯èƒ½éœ€è¦ç­‰å¾…å½“å‰ä»»åŠ¡å®Œæˆ")


def main():
    root = tk.Tk()
    app = DeepSeekOCRVLLMGUI(root)
    root.mainloop()


if __name__ == "__main__":
    main()
