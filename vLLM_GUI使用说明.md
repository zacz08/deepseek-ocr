# DeepSeek OCR vLLM GUI 使用说明

## 🚀 新功能亮点

相比 HuggingFace 版本，vLLM 版本 GUI 增加了：

### ✨ 核心新功能
1. **PDF 文档处理** - 自动将 PDF 转换为图像并逐页识别
2. **批量图片处理** - 一次性处理整个文件夹的图片
3. **三种输入模式** - 单图、PDF、批量，灵活切换
4. **更快的速度** - 基于 vLLM 引擎，推理速度显著提升
5. **高并发支持** - 可配置并发数，充分利用 GPU

### 🎯 性能优势
- ⚡ **速度提升 2-5倍** - vLLM 优化的推理引擎
- 💾 **内存优化** - 更高效的 GPU 内存管理
- 🔄 **批量处理** - 原生支持批量任务

---

## 📋 系统要求

### 必需
- Windows 10/11 (64位)
- Python 3.8-3.12
- NVIDIA GPU (推荐 8GB+ 显存)
- CUDA 11.8 或 12.1

### 推荐配置
- 16GB+ 系统内存
- RTX 3090 / 4090 或更高
- SSD 硬盘

---

## 🔧 安装依赖

### 1. 安装基础依赖
```bash
conda activate deepseek-ocr
pip install vllm
pip install PyMuPDF  # PDF 处理
```

### 2. 验证安装
```bash
python -c "import vllm; print('vLLM installed successfully')"
python -c "import fitz; print('PyMuPDF installed successfully')"
```

---

## 🎮 启动方式

### 方式1：批处理文件（推荐）
```bash
双击 run_gui_vllm.bat
```

### 方式2：命令行
```bash
cd DeepSeek-OCR-master\DeepSeek-OCR-vllm
python gui_ocr_vllm.py
```

### 方式3：从项目根目录
```bash
python DeepSeek-OCR-master\DeepSeek-OCR-vllm\gui_ocr_vllm.py
```

---

## 📖 使用教程

### 第一步：加载模型

1. **配置模型参数**
   - 模型路径：默认 `deepseek-ai/DeepSeek-OCR`
   - GPU内存利用率：0.75 (可调整 0.1-0.95)
   - 最大并发：100 (根据显存调整)

2. **点击"加载模型"**
   - 首次需要下载模型（5-10 GB）
   - 等待 2-5 分钟加载完成
   - 显示"状态: 已加载 (vLLM)"即成功

### 第二步：选择输入类型

#### 🖼️ 单图模式
- 选择"图片"单选按钮
- 点击"选择图片"选择单张图片
- 支持格式：JPG, PNG, BMP, TIFF

#### 📄 PDF模式
- 选择"PDF"单选按钮
- 点击"选择PDF"选择PDF文件
- 自动逐页处理
- 可调整 DPI (72-300)

#### 📁 批量模式
- 选择"批量图片"单选按钮
- 点击"选择文件夹"选择包含图片的文件夹
- 自动处理文件夹内所有图片

### 第三步：配置参数

#### OCR 参数
- **base_size**: 基础尺寸 (512/640/1024/1280)
- **image_size**: 处理尺寸 (512/640/1024/1280)
- **PDF DPI**: PDF转图片分辨率 (72-300)
- **Crop Mode**: 启用裁剪模式
- **保存结果**: 保存Markdown文件
- **保存可视化**: 保存带标注的图片

#### 预设配置
- **Gundam** (推荐): 1024/640/True - 速度与质量平衡
- **Tiny**: 512/512/False - 最快速度
- **Small**: 640/640/False - 快速
- **Base**: 1024/1024/False - 标准质量
- **Large**: 1280/1280/False - 最高质量

#### 提示词模板
- `<image>\n<|grounding|>Convert the document to markdown.` - 文档转Markdown
- `<image>\nFree OCR.` - 纯文字识别
- `<image>\n<|grounding|>OCR this image.` - 带定位的OCR
- `<image>\nParse the figure.` - 图表解析
- `<image>\nDescribe this image in detail.` - 图像描述

### 第四步：开始识别

1. 设置输出目录（默认 `./output`）
2. 点击"开始识别"按钮
3. 查看实时日志输出
4. 等待识别完成
5. 点击"打开输出目录"查看结果

---

## 📊 输出文件说明

### 单图模式输出
```
output/
├── result.md              # 识别结果（Markdown格式）
└── images/                # 提取的子图片（如果有）
    ├── 0.jpg
    ├── 1.jpg
    └── ...
```

### PDF模式输出
```
output/
├── page_001.md           # 第1页结果
├── page_002.md           # 第2页结果
├── ...
├── all_pages.md          # 所有页面合并结果
└── images/               # 提取的图片
```

### 批量模式输出
```
output/
├── image1.md             # 图片1的结果
├── image2.md             # 图片2的结果
├── ...
└── images/               # 提取的图片
```

---

## 🎯 使用场景示例

### 场景1：扫描文档识别
```
输入类型：单图/PDF
提示词：<image>\n<|grounding|>Convert the document to markdown.
预设：Base 或 Gundam
```

### 场景2：快速文字提取
```
输入类型：批量图片
提示词：<image>\nFree OCR.
预设：Tiny 或 Small
```

### 场景3：学术论文处理
```
输入类型：PDF
提示词：<image>\n<|grounding|>Convert the document to markdown.
预设：Large
PDF DPI：200 或 300
```

### 场景4：图表解析
```
输入类型：单图
提示词：<image>\nParse the figure.
预设：Base 或 Large
```

---

## ⚙️ 高级配置

### GPU 内存优化

#### 显存充足 (16GB+)
```
GPU内存利用率: 0.85-0.95
最大并发: 100-200
预设: Large
```

#### 显存中等 (8-16GB)
```
GPU内存利用率: 0.75-0.85
最大并发: 50-100
预设: Base 或 Gundam
```

#### 显存较小 (6-8GB)
```
GPU内存利用率: 0.6-0.75
最大并发: 20-50
预设: Small
```

### PDF DPI 选择

| DPI | 用途 | 文件大小 | 质量 |
|-----|------|---------|------|
| 72  | 预览、草稿 | 小 | 低 |
| 96  | 一般文档 | 小 | 中 |
| 144 | **推荐默认** | 中 | 好 |
| 200 | 高质量文档 | 大 | 很好 |
| 300 | 扫描件、印刷品 | 很大 | 最佳 |

---

## 🐛 故障排除

### 问题1：模型加载失败
**可能原因：**
- 网络问题
- 显存不足
- CUDA版本不匹配

**解决方案：**
```bash
# 检查CUDA
python -c "import torch; print(torch.cuda.is_available())"

# 降低GPU内存利用率
GPU内存利用率: 0.6

# 检查vLLM安装
pip install vllm --upgrade
```

### 问题2：PDF处理失败
**可能原因：**
- 缺少 PyMuPDF
- PDF文件损坏
- 内存不足

**解决方案：**
```bash
# 安装/重装 PyMuPDF
pip install PyMuPDF --upgrade

# 降低PDF DPI
PDF DPI: 96 或 72
```

### 问题3：识别速度慢
**优化建议：**
1. 降低并发数（减少显存占用）
2. 使用较小的预设（Tiny/Small）
3. 关闭不必要的保存选项
4. 检查是否正确使用GPU

### 问题4：显存溢出 (OOM)
**解决方案：**
```
1. 降低 GPU内存利用率 → 0.6-0.7
2. 减少 最大并发 → 20-50
3. 使用更小的预设 → Tiny 或 Small
4. 降低 PDF DPI → 96
5. 关闭其他占用显存的程序
```

### 问题5：批量处理中断
**检查事项：**
- 确认所有图片格式正确
- 检查文件权限
- 查看日志中的错误信息
- 确保有足够磁盘空间

---

## 🔄 与 HF 版本对比

| 特性 | vLLM版本 | HF版本 |
|------|---------|--------|
| **速度** | ⚡⚡⚡⚡⚡ | ⚡⚡⚡ |
| **PDF支持** | ✅ 原生支持 | ❌ 不支持 |
| **批量处理** | ✅ 优化 | ⚠️ 基础 |
| **并发处理** | ✅ 高并发 | ❌ 单线程 |
| **内存效率** | ✅ 高效 | ⚠️ 一般 |
| **易用性** | ⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ |
| **稳定性** | ⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ |

### 选择建议

**使用 vLLM 版本：**
- ✅ 处理 PDF 文档
- ✅ 批量处理大量图片
- ✅ 需要最快速度
- ✅ 有良好的GPU资源

**使用 HF 版本：**
- ✅ 首次使用/学习
- ✅ 单张图片处理
- ✅ 简单任务
- ✅ GPU资源有限

---

## 📝 注意事项

### ⚠️ 重要提示

1. **首次使用**
   - 确保网络通畅（下载模型）
   - 预留足够时间（5-15分钟）
   - 检查CUDA环境

2. **PDF处理**
   - 大文件需要更多时间
   - 建议先用低DPI测试
   - 注意磁盘空间

3. **批量处理**
   - 建议先测试单张
   - 准备足够的存储空间
   - 可能需要较长时间

4. **性能调优**
   - 根据显存调整参数
   - 监控GPU使用率
   - 平衡速度与质量

---

## 🎓 最佳实践

### 文档处理流程
```
1. 用 Tiny 预设快速预览
2. 确认效果后用 Base/Large 正式处理
3. PDF 先测试前几页
4. 批量处理前备份原文件
```

### 参数选择指南
```
快速预览：Tiny + DPI 72
一般文档：Gundam + DPI 144
高质量：Large + DPI 200+
批量处理：Small/Base + 适中DPI
```

---

## 📞 技术支持

### 查看日志
程序界面下方的"运行日志"区域会显示：
- 模型加载进度
- 处理过程详情
- 错误信息
- 完成状态

### 获取帮助
1. 查看日志中的详细错误
2. 检查本文档的故障排除部分
3. 确认环境配置正确
4. 查看 vLLM 官方文档

---

## 🚀 快速开始示例

### 示例1：识别单张扫描文档
```
1. 启动 GUI
2. 加载模型（等待完成）
3. 选择"图片"
4. 选择您的扫描图片
5. 预设选"Base"
6. 提示词：默认（转Markdown）
7. 点击"开始识别"
8. 等待完成，打开输出目录查看
```

### 示例2：处理多页PDF
```
1. 启动 GUI
2. 加载模型
3. 选择"PDF"
4. 选择您的PDF文件
5. PDF DPI：144
6. 预设选"Gundam"
7. 点击"开始识别"
8. 查看日志监控进度
9. 完成后查看 all_pages.md
```

### 示例3：批量处理照片
```
1. 将所有图片放在一个文件夹
2. 启动 GUI，加载模型
3. 选择"批量图片"
4. 选择图片文件夹
5. 预设选"Small"（速度快）
6. 提示词："Free OCR"
7. 点击"开始识别"
8. 等待批量处理完成
```

---

**祝您使用愉快！** 🎉

如果有任何问题，请查看日志输出获取详细信息。
